{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50153835",
   "metadata": {},
   "source": [
    "# M161 first question notebook- best model LogisticRegrgessionCV , 0.99969 accuracy, 50000 instances, max_features=15000 vectorization\n",
    "\n",
    "### Data from D:\\Github\\bigData\\part1\\joblibCache\\dataTrain_cleaned.joblib\n",
    "(duplicate removal and text processed already including stemming an d lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff19713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227464</td>\n",
       "      <td>come cabl groceri overlord</td>\n",
       "      <td>subscrib one three dink compar speak cabl abl ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244074</td>\n",
       "      <td>presid react happi</td>\n",
       "      <td>presid react happi singer presid took twitter ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60707</td>\n",
       "      <td>wildlif servic</td>\n",
       "      <td>fish wildlif servic comment period addit day p...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27883</td>\n",
       "      <td>launch</td>\n",
       "      <td>natur social medium often sourc real time brea...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169596</td>\n",
       "      <td>u new york casino</td>\n",
       "      <td>u new york casino latest news top deck world e...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                       Title  \\\n",
       "0  227464  come cabl groceri overlord   \n",
       "1  244074          presid react happi   \n",
       "2   60707              wildlif servic   \n",
       "3   27883                      launch   \n",
       "4  169596           u new york casino   \n",
       "\n",
       "                                             Content          Label  \n",
       "0  subscrib one three dink compar speak cabl abl ...  Entertainment  \n",
       "1  presid react happi singer presid took twitter ...  Entertainment  \n",
       "2  fish wildlif servic comment period addit day p...     Technology  \n",
       "3  natur social medium often sourc real time brea...     Technology  \n",
       "4  u new york casino latest news top deck world e...       Business  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "dataTrain = joblib.load(r'joblibCache\\dataTrain_cleaned.joblib')\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f50c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset shape (stratified): (50000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Stratify and keep 50000 instances based on the 'Label' column\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratify and sample 50000 instances\n",
    "stratified_data, _ = train_test_split(\n",
    "    dataTrain,\n",
    "    train_size=50000,\n",
    "    stratify=dataTrain['Label'],\n",
    "    random_state=42\n",
    ")\n",
    "dataTrain = stratified_data.reset_index(drop=True)\n",
    "print(f\"Subset shape (stratified): {dataTrain.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888cc01",
   "metadata": {},
   "source": [
    "### Just printing out the firtst 5 columns to see what happend to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cb3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   Id       50000 non-null  int64\n",
      " 1   Title    50000 non-null  str  \n",
      " 2   Content  50000 non-null  str  \n",
      " 3   Label    50000 non-null  str  \n",
      "dtypes: int64(1), str(3)\n",
      "memory usage: 1.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataTrain.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d8862",
   "metadata": {},
   "source": [
    "## Starting future extraction (converting text to numbers for ML algorythms to run)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff593d17",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "\n",
    "We will now use TF-IDF vectorization instead of Bag of Words to represent the text data for classification. TF-IDF often improves performance by reducing the impact of common words and highlighting more informative terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6b4208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (50000, 15000)\n",
      "Feature names (first 20): ['aa' 'abandon' 'abbey' 'abdomen' 'abdomin' 'abid' 'abil' 'abl'\n",
      " 'abl access' 'abl buy' 'abl creat' 'abl find' 'abl get' 'abl keep'\n",
      " 'abl make' 'abl see' 'abl take' 'abl use' 'abl watch' 'abnorm']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine Title and Content if not already done\n",
    "if 'Combined' not in dataTrain.columns:\n",
    "    dataTrain['Combined'] = dataTrain['Title'].fillna('') + ' ' + dataTrain['Content'].fillna('')\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "# You can tune max_features, ngram_range, etc. for further improvement\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=15000)\n",
    "dataTrain_tfidf = vectorizer.fit_transform(dataTrain['Combined'])\n",
    "\n",
    "print('TF-IDF matrix shape:', dataTrain_tfidf.shape)\n",
    "print('Feature names (first 20):', vectorizer.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641549a",
   "metadata": {},
   "source": [
    "### Logistic Regression with Built-in Cross-Validation (LogisticRegressionCV)\n",
    "\n",
    "We will now use `LogisticRegressionCV` from scikit-learn, which performs cross-validated logistic regression and automatically tunes the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe1db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\bigData\\venvEnv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1780: FutureWarning: The default value for l1_ratios will change from None to (0.0,) in version 1.10. From version 1.10 onwards, only array-like with values in [0, 1] will be allowed, None will be forbidden. To avoid this warning, explicitly set a value, e.g. l1_ratios=(0,).\n",
      "  warnings.warn(\n",
      "d:\\Github\\bigData\\venvEnv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1823: FutureWarning: The fitted attributes of LogisticRegressionCV will be simplified in scikit-learn 1.10 to remove redundancy. Set`use_legacy_attributes=False` to enable the new behavior now, or set it to `True` to silence this warning during the transition period while keeping the deprecated behavior for the time being. The default value of use_legacy_attributes will change from True to False in scikit-learn 1.10. See the docstring of LogisticRegressionCV for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C values per class: [2.7825594 2.7825594 2.7825594 2.7825594]\n",
      "\n",
      " ***********************\n",
      "\n",
      "Classification Report (LogisticRegressionCV, 5-fold CV):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.96      0.96      0.96     11123\n",
      "Entertainment       0.99      0.99      0.99     20017\n",
      "       Health       0.97      0.99      0.98      5374\n",
      "   Technology       0.97      0.97      0.97     13486\n",
      "\n",
      "     accuracy                           0.98     50000\n",
      "    macro avg       0.97      0.98      0.97     50000\n",
      " weighted avg       0.98      0.98      0.98     50000\n",
      "\n",
      "\n",
      " classification accuracy a= 0.97574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assume the target column is named 'Label' (change if needed)\n",
    "if 'Label' not in dataTrain.columns:\n",
    "    print(\"ERROR: 'Label' column not found in dataTrain. Please check your dataset.\")\n",
    "else:\n",
    "    X = dataTrain_tfidf\n",
    "    y = dataTrain['Label']\n",
    "    clf_cv = LogisticRegressionCV(cv=5, max_iter=1000, random_state=42,class_weight='balanced',scoring='accuracy', n_jobs= 6)\n",
    "    clf_cv.fit(X, y)\n",
    "    y_pred_cv = clf_cv.predict(X)\n",
    "    print(\"Best C values per class:\", clf_cv.C_)\n",
    "    print('\\n ***********************')\n",
    "    \n",
    "\n",
    "    print(\"\\nClassification Report (LogisticRegressionCV, 5-fold CV):\\n\", classification_report(y, y_pred_cv, zero_division=0))\n",
    "    \n",
    "    print ('\\n classification accuracy a=', clf_cv.score(X, y))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064ddb3",
   "metadata": {},
   "source": [
    "## Writing test predictions to file testSet_categories.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bafee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load test data\n",
    "# test_file_path = 'bigdata2025classification/test_without_labels.csv'\n",
    "# test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "# # Apply the same text preprocessing to the test data\n",
    "\n",
    "# # Remove non-English words\n",
    "# test_data['Title'] = test_data['Title'].apply(remove_non_english_words)\n",
    "# test_data['Content'] = test_data['Content'].apply(remove_non_english_words)\n",
    "\n",
    "# # Clean text (expand contractions, lowercase, remove special chars, stopwords, lemmatize, stem)\n",
    "# for col in ['Title', 'Content']:\n",
    "#     test_data[col] = test_data[col].astype(str).apply(clean_text)\n",
    "\n",
    "# # Combine Title and Content for test data (same as training)\n",
    "# test_data['Combined'] = test_data['Title'].fillna('') + ' ' + test_data['Content'].fillna('')\n",
    "\n",
    "# # Apply the same TF-IDF vectorizer to test data\n",
    "# test_tfidf = vectorizer.transform(test_data['Combined'])\n",
    "\n",
    "# # Predict labels using the trained classifier\n",
    "# test_pred = clf_cv.predict(test_tfidf)\n",
    "\n",
    "# # Prepare output DataFrame\n",
    "# output_df = pd.DataFrame({\n",
    "#     'Id': test_data['Id'],\n",
    "#     'Predicted': test_pred\n",
    "# })\n",
    "\n",
    "# # Write predictions to CSV\n",
    "# output_df.to_csv('testSet_categories.csv', index=False)\n",
    "# print(\"Predictions written to testSet_categories.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvEnv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
