{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50153835",
   "metadata": {},
   "source": [
    "# M161 first question notebook- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff19713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227464</td>\n",
       "      <td>come cabl groceri overlord</td>\n",
       "      <td>subscrib one three dink compar speak cabl abl ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244074</td>\n",
       "      <td>presid react happi</td>\n",
       "      <td>presid react happi singer presid took twitter ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60707</td>\n",
       "      <td>wildlif servic</td>\n",
       "      <td>fish wildlif servic comment period addit day p...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27883</td>\n",
       "      <td>launch</td>\n",
       "      <td>natur social medium often sourc real time brea...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169596</td>\n",
       "      <td>u new york casino</td>\n",
       "      <td>u new york casino latest news top deck world e...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                       Title  \\\n",
       "0  227464  come cabl groceri overlord   \n",
       "1  244074          presid react happi   \n",
       "2   60707              wildlif servic   \n",
       "3   27883                      launch   \n",
       "4  169596           u new york casino   \n",
       "\n",
       "                                             Content          Label  \n",
       "0  subscrib one three dink compar speak cabl abl ...  Entertainment  \n",
       "1  presid react happi singer presid took twitter ...  Entertainment  \n",
       "2  fish wildlif servic comment period addit day p...     Technology  \n",
       "3  natur social medium often sourc real time brea...     Technology  \n",
       "4  u new york casino latest news top deck world e...       Business  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "dataTrain = joblib.load(r'joblibCache\\dataTrain_cleaned.joblib')\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f50c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratify and keep 50000 instances based on the 'Label' column\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Stratify and sample 50000 instances\n",
    "# stratified_data, _ = train_test_split(\n",
    "#     dataTrain,\n",
    "#     train_size=50000,\n",
    "#     stratify=dataTrain['Label'],\n",
    "#     random_state=42\n",
    "# )\n",
    "# dataTrain = stratified_data.reset_index(drop=True)\n",
    "# print(f\"Subset shape (stratified): {dataTrain.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888cc01",
   "metadata": {},
   "source": [
    "### Just printing out the firtst 5 columns to see what happend to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68cb3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 111220 entries, 0 to 111219\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype\n",
      "---  ------   --------------   -----\n",
      " 0   Id       111220 non-null  int64\n",
      " 1   Title    111220 non-null  str  \n",
      " 2   Content  111220 non-null  str  \n",
      " 3   Label    111220 non-null  str  \n",
      "dtypes: int64(1), str(3)\n",
      "memory usage: 3.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataTrain.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd21f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP Classifier...\n",
      "Accuracy: 0.9446592339507283\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.92      0.89      0.91      4948\n",
      "Entertainment       0.98      0.98      0.98      8905\n",
      "       Health       0.94      0.95      0.95      2391\n",
      "   Technology       0.91      0.94      0.93      6000\n",
      "\n",
      "     accuracy                           0.94     22244\n",
      "    macro avg       0.94      0.94      0.94     22244\n",
      " weighted avg       0.94      0.94      0.94     22244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. PREPARE DATA FOR WORD2VEC\n",
    "# Word2Vec requires a list of tokens (words), not just raw strings.\n",
    "# Since your data looks already cleaned, we can just split by whitespace.\n",
    "tokenized_content = dataTrain['Content'].apply(lambda x: x.split())\n",
    "\n",
    "# 2. TRAIN WORD2VEC MODEL\n",
    "# vector_size=100: Dimension of the dense vector\n",
    "# window=5: Distance between current and predicted word\n",
    "# min_count=2: Ignores all words with total frequency lower than this\n",
    "# workers=4: Number of threads to use\n",
    "w2v_model = Word2Vec(sentences=tokenized_content, vector_size=300, window=5, min_count=2, workers=4)\n",
    "\n",
    "# 3. VECTORIZE DOCUMENTS (AVERAGE WORD VECTORS)\n",
    "# We need to turn each document into a single vector to feed into the MLP.\n",
    "# A common strategy is to average the vectors of all words in the document.\n",
    "\n",
    "def document_vectorizer(tokens, model):\n",
    "    # Filter out words that are not in the Word2Vec vocabulary\n",
    "    valid_words = [word for word in tokens if word in model.wv.key_to_index]\n",
    "    \n",
    "    if valid_words:\n",
    "        # Calculate the mean of vectors for valid words\n",
    "        return np.mean(model.wv[valid_words], axis=0)\n",
    "    else:\n",
    "        # Return a vector of zeros if no words are found in the vocab\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Apply the vectorizer to create the input feature matrix X\n",
    "X = np.array([document_vectorizer(tokens, w2v_model) for tokens in tokenized_content])\n",
    "y = dataTrain['Label']\n",
    "\n",
    "# 4. SPLIT DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 5. TRAIN MLP CLASSIFIER\n",
    "# hidden_layer_sizes=(100, 50): Two hidden layers with 100 and 50 neurons\n",
    "# max_iter=300: Maximum number of iterations (epochs)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "print(\"Training MLP Classifier...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 6. EVALUATE\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43033237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP Classifier...\n",
      "Accuracy: 0.9540999820176227\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.93      0.92      0.92      4948\n",
      "Entertainment       0.98      0.98      0.98      8905\n",
      "       Health       0.96      0.96      0.96      2391\n",
      "   Technology       0.93      0.94      0.94      6000\n",
      "\n",
      "     accuracy                           0.95     22244\n",
      "    macro avg       0.95      0.95      0.95     22244\n",
      " weighted avg       0.95      0.95      0.95     22244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. TRAIN MLP CLASSIFIER\n",
    "# hidden_layer_sizes=(100, 50): Two hidden layers with 100 and 50 neurons\n",
    "# max_iter=300: Maximum number of iterations (epochs)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(500, 250), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "print(\"Training MLP Classifier...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 6. EVALUATE\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522416ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP Classifier...\n",
      "Accuracy: 0.9503686387340406\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.93      0.91      0.92      4948\n",
      "Entertainment       0.98      0.98      0.98      8905\n",
      "       Health       0.95      0.96      0.95      2391\n",
      "   Technology       0.93      0.94      0.93      6000\n",
      "\n",
      "     accuracy                           0.95     22244\n",
      "    macro avg       0.95      0.95      0.95     22244\n",
      " weighted avg       0.95      0.95      0.95     22244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. PREPARE DATA FOR WORD2VEC\n",
    "# Word2Vec requires a list of tokens (words), not just raw strings.\n",
    "# Since your data looks already cleaned, we can just split by whitespace.\n",
    "tokenized_content = dataTrain['Content'].apply(lambda x: x.split())\n",
    "\n",
    "# 2. TRAIN WORD2VEC MODEL\n",
    "# vector_size=100: Dimension of the dense vector\n",
    "# window=5: Distance between current and predicted word\n",
    "# min_count=2: Ignores all words with total frequency lower than this\n",
    "# workers=4: Number of threads to use\n",
    "w2v_model = Word2Vec(sentences=tokenized_content, vector_size=1000, window=5, min_count=2, workers=4)\n",
    "\n",
    "# 3. VECTORIZE DOCUMENTS (AVERAGE WORD VECTORS)\n",
    "# We need to turn each document into a single vector to feed into the MLP.\n",
    "# A common strategy is to average the vectors of all words in the document.\n",
    "\n",
    "def document_vectorizer(tokens, model):\n",
    "    # Filter out words that are not in the Word2Vec vocabulary\n",
    "    valid_words = [word for word in tokens if word in model.wv.key_to_index]\n",
    "    \n",
    "    if valid_words:\n",
    "        # Calculate the mean of vectors for valid words\n",
    "        return np.mean(model.wv[valid_words], axis=0)\n",
    "    else:\n",
    "        # Return a vector of zeros if no words are found in the vocab\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Apply the vectorizer to create the input feature matrix X\n",
    "X = np.array([document_vectorizer(tokens, w2v_model) for tokens in tokenized_content])\n",
    "y = dataTrain['Label']\n",
    "\n",
    "# 4. SPLIT DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 5. TRAIN MLP CLASSIFIER\n",
    "# hidden_layer_sizes=(100, 50): Two hidden layers with 100 and 50 neurons\n",
    "# max_iter=300: Maximum number of iterations (epochs)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "print(\"Training MLP Classifier...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 6. EVALUATE\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvEnv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
